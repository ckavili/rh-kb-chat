{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678dd73d-9d74-45f6-8e07-980423767da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b8f9d-32cc-49a3-ab67-51e9929ec3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DOCUMENTATION_URL = \"https://docs.redhat.com/en/documentation\"\n",
    "\n",
    "def format_product_name(product_name):\n",
    "    \"\"\"Convert product name to match documentation URL format.\"\"\"\n",
    "    return product_name.lower().replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffa078-6294-4b16-8dcc-6d85c6576d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products():\n",
    "    \"\"\"Scrapes product names and full names from the products page.\"\"\"\n",
    "    response = requests.get(BASE_DOCUMENTATION_URL)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to retrieve products page: {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    products = {}\n",
    "\n",
    "    for link in soup.select(\"a\"):  # Adjust the selector based on site structure\n",
    "        href = link.get(\"href\")\n",
    "        if href and href.startswith(\"/en/documentation/\"):  # Extract valid product links\n",
    "            product_name = href.split(\"/\")[-1]  # Extract collection_base_name\n",
    "            product_full_name = link.text.strip()\n",
    "            # products[product_name] = product_full_name\n",
    "            products[product_full_name] = product_name\n",
    "\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da12288-679c-45a0-81f0-79abd3882759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_versions(product_name, initial_version):\n",
    "    \"\"\"Scrape the documentation page to extract available versions.\"\"\"\n",
    "    formatted_name = format_product_name(product_name)\n",
    "    doc_url = f\"{BASE_DOCUMENTATION_URL}/{formatted_name}/{initial_version}\"\n",
    "    \n",
    "    response = requests.get(doc_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {doc_url}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Identify the dropdown element containing versions\n",
    "    version_dropdown = soup.find(\"select\", {\"id\": \"product_version\"})  # Adjust selector if needed\n",
    "\n",
    "    if not version_dropdown:\n",
    "        print(f\"No version dropdown found for {formatted_name}\")\n",
    "        return []\n",
    "\n",
    "    versions = [option.text.strip() for option in version_dropdown.find_all(\"option\")]\n",
    "    \n",
    "    # Sort versions based on numeric parts\n",
    "    sorted_versions = sorted(versions, key=lambda x: [int(n) for n in x.split(\".\") if n.isdigit()], reverse=True)\n",
    "    \n",
    "    return sorted_versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a0087-704c-41d7-8c8a-5062b05c5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_product_data(products):\n",
    "    \"\"\"Fetch and structure product documentation details, saving each as a separate file.\"\"\"\n",
    "    for product_name, initial_version in products.items():\n",
    "        versions = get_versions(product_name, initial_version)\n",
    "        if not versions:\n",
    "            continue\n",
    "\n",
    "        # Determine store_directive for each version\n",
    "        version_data = []\n",
    "        for index, version in enumerate(versions):\n",
    "            store_directive = \"create_or_keep\" if index < 2 else \"delete\"\n",
    "            version_data.append({\n",
    "                \"version_number\": version,\n",
    "                \"store_directive\": store_directive,\n",
    "                \"sources\": [{\"ingestion_type\": \"redhat_doc\", \"language\": \"en-US\"}]\n",
    "            })\n",
    "\n",
    "        product_data = {\n",
    "            \"collection_base_name\": format_product_name(product_name),\n",
    "            \"collection_full_name\": product_name,\n",
    "            \"common_sources\": [],\n",
    "            \"versions\": version_data\n",
    "        }\n",
    "\n",
    "        # Save to a JSON file named after the formatted product name\n",
    "        file_name = f\"{format_product_name(product_name)}.json\"\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(product_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Saved {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b6b4a-cfe2-403c-9bc5-2b768cc13400",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_json = save_product_data(get_products())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
